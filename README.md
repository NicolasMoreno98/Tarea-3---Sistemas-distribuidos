# Tarea 3 - An√°lisis de Texto con Hadoop y Apache Pig
## Sistemas Distribuidos 2025-2

Este proyecto implementa un sistema de an√°lisis batch para comparar respuestas de Yahoo! Answers vs respuestas generadas por un LLM, utilizando Hadoop HDFS y Apache Pig para procesamiento distribuido.

---

## Descripcion

El sistema realiza an√°lisis de frecuencia de palabras (WordCount) sobre dos conjuntos de datos:
1. **Respuestas de usuarios de Yahoo! Answers**
2. **Respuestas generadas por un LLM**

El procesamiento incluye:
- Tokenizacion de texto
- Limpieza (minusculas, eliminacion de puntuacion)
- Filtrado de stopwords (espanol e ingles)
- Conteo de frecuencia de palabras
- Analisis comparativo entre ambos conjuntos

---

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL    ‚îÇ ‚Üê Almacenamiento persistente
‚îÇ   (responses)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì Exportaci√≥n
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Archivos TXT   ‚îÇ ‚Üê human_answers.txt, llm_answers.txt
‚îÇ  (HDFS Input)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì Carga a HDFS
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Hadoop HDFS    ‚îÇ ‚Üê Almacenamiento distribuido
‚îÇ  NameNode +     ‚îÇ
‚îÇ  DataNode       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì Procesamiento MapReduce
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Apache Pig     ‚îÇ ‚Üê Scripts de an√°lisis
‚îÇ  (WordCount)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì Resultados
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Output (HDFS)   ‚îÇ ‚Üê Resultados del an√°lisis
‚îÇ /output/...     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Componentes

### Servicios Docker

1. **postgres**: Base de datos PostgreSQL para almacenar los datos de `response.json`
2. **dataloader**: Contenedor que carga `response.json` a PostgreSQL
3. **dataexporter**: Exporta respuestas de PostgreSQL a archivos de texto
4. **namenode**: Hadoop NameNode (coordinador de HDFS)
5. **datanode**: Hadoop DataNode (almacenamiento de datos)
6. **pig_analysis**: Ejecuta scripts de Apache Pig para an√°lisis

### Archivos de Configuraci√≥n

- `docker-compose.yml`: Orquestaci√≥n de servicios
- `docker/Dockerfile.hadoop`: Imagen con Hadoop 3.3.6 y Pig 0.17.0
- `docker/Dockerfile.dataloader`: Imagen para carga de datos
- `docker/hadoop-config/*.xml`: Configuraciones de Hadoop (core-site, hdfs-site, etc.)

### Scripts

- `scripts/load_data.py`: Carga `response.json` a PostgreSQL
- `scripts/export_data.py`: Exporta datos a archivos de texto
- `scripts/start-namenode.sh`: Inicializa NameNode de Hadoop
- `scripts/start-datanode.sh`: Inicializa DataNode de Hadoop
- `scripts/run-analysis.sh`: Ejecuta el an√°lisis completo con Pig

### Scripts de Pig

- `pig/analyze_human.pig`: An√°lisis de respuestas humanas
- `pig/analyze_llm.pig`: An√°lisis de respuestas LLM
- `pig/compare_results.pig`: Comparaci√≥n entre ambos conjuntos

---

## Requisitos

- Docker Desktop
- Docker Compose
- Al menos 8 GB de RAM disponible para Docker
- 10 GB de espacio en disco

---

## Instalacion y Ejecucion

### 1. Clonar/Ubicar el proyecto

Aseg√∫rate de tener todos los archivos en el directorio `T3`:

```
T3/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ response.json           ‚Üê Archivo de datos (9738 respuestas)
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.hadoop
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.dataloader
‚îÇ   ‚îî‚îÄ‚îÄ hadoop-config/
‚îÇ       ‚îú‚îÄ‚îÄ core-site.xml
‚îÇ       ‚îú‚îÄ‚îÄ hdfs-site.xml
‚îÇ       ‚îú‚îÄ‚îÄ mapred-site.xml
‚îÇ       ‚îî‚îÄ‚îÄ yarn-site.xml
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ load_data.py
‚îÇ   ‚îú‚îÄ‚îÄ export_data.py
‚îÇ   ‚îú‚îÄ‚îÄ start-namenode.sh
‚îÇ   ‚îú‚îÄ‚îÄ start-datanode.sh
‚îÇ   ‚îî‚îÄ‚îÄ run-analysis.sh
‚îú‚îÄ‚îÄ pig/
‚îÇ   ‚îú‚îÄ‚îÄ analyze_human.pig
‚îÇ   ‚îú‚îÄ‚îÄ analyze_llm.pig
‚îÇ   ‚îî‚îÄ‚îÄ compare_results.pig
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îî‚îÄ‚îÄ schema.sql
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ stopwords.txt
‚îî‚îÄ‚îÄ README.md
```

### 2. Construir las im√°genes Docker

```powershell
docker-compose build
```

**Nota**: Este proceso puede tardar 10-15 minutos la primera vez, ya que descarga Hadoop (>1GB) y Pig.

### 3. Iniciar todos los servicios

```powershell
docker-compose up -d
```

Esto iniciar√° los servicios en el siguiente orden:
1. PostgreSQL
2. Dataloader (carga `response.json`)
3. Dataexporter (exporta a TXT)
4. NameNode y DataNode (Hadoop)
5. Pig Analysis (ejecuta an√°lisis)

### 4. Verificar el progreso

Puedes ver los logs en tiempo real:

```powershell
# Ver todos los logs
docker-compose logs -f

# Ver solo los logs del an√°lisis de Pig
docker-compose logs -f pig_analysis

# Ver logs del NameNode
docker-compose logs -f namenode
```

---

## Acceso a Interfaces Web

Una vez que los servicios est√©n corriendo:

- **Hadoop NameNode UI**: http://localhost:9870
  - Ver estado de HDFS
  - Explorar archivos: http://localhost:9870/explorer.html

- **YARN ResourceManager**: http://localhost:8088
  - Ver jobs de MapReduce en ejecuci√≥n
  - Historial de jobs

- **DataNode UI**: http://localhost:9864

---

## Resultados del Analisis

### Ubicaci√≥n de Resultados en HDFS

Los resultados se guardan en HDFS bajo `/output/`:

```
/output/
‚îú‚îÄ‚îÄ human_wordcount/       ‚Üê Conteo completo de palabras (respuestas humanas)
‚îú‚îÄ‚îÄ human_top100/          ‚Üê Top 100 palabras m√°s frecuentes (humanos)
‚îú‚îÄ‚îÄ llm_wordcount/         ‚Üê Conteo completo de palabras (respuestas LLM)
‚îú‚îÄ‚îÄ llm_top100/            ‚Üê Top 100 palabras m√°s frecuentes (LLM)
‚îú‚îÄ‚îÄ comparison/            ‚Üê Comparaci√≥n completa palabra por palabra
‚îî‚îÄ‚îÄ top_differences/       ‚Üê Top 50 palabras con mayor diferencia
```

### Ver Resultados

#### Opci√≥n 1: Desde los logs del an√°lisis

Los resultados principales se muestran autom√°ticamente al finalizar:

```powershell
docker-compose logs pig_analysis | tail -100
```

#### Opci√≥n 2: Conectarse al contenedor

```powershell
# Conectarse al NameNode
docker exec -it hadoop_namenode bash

# Ver top 20 palabras en respuestas humanas
hdfs dfs -cat /output/human_top100/part-r-00000 | head -20

# Ver top 20 palabras en respuestas LLM
hdfs dfs -cat /output/llm_top100/part-r-00000 | head -20

# Ver palabras con mayor diferencia
hdfs dfs -cat /output/top_differences/part-r-00000 | head -20

# Descargar resultados completos
hdfs dfs -get /output/human_wordcount ./results_human
hdfs dfs -get /output/llm_wordcount ./results_llm
hdfs dfs -get /output/comparison ./results_comparison
```

#### Opci√≥n 3: Copiar resultados al host

```powershell
# Crear directorio para resultados
New-Item -ItemType Directory -Force -Path ".\results"

# Copiar desde el contenedor
docker cp hadoop_namenode:/opt/hadoop/results_human .\results\
docker cp hadoop_namenode:/opt/hadoop/results_llm .\results\
docker cp hadoop_namenode:/opt/hadoop/results_comparison .\results\
```

---

## Formato de Resultados

### WordCount (human_wordcount, llm_wordcount)

Formato: `palabra\tconteo`

Ejemplo:
```
answer	5234
question	4891
information	3456
help	2987
...
```

### Comparaci√≥n (comparison, top_differences)

Formato: `palabra\tconteo_humano\tconteo_llm\tdiferencia_absoluta`

Ejemplo:
```
answer	5234	4123	1111
question	4891	5234	343
information	3456	2987	469
...
```

---

## Comandos Utiles

### Gesti√≥n de Contenedores

```powershell
# Iniciar servicios
docker-compose up -d

# Detener servicios
docker-compose down

# Reiniciar un servicio espec√≠fico
docker-compose restart namenode

# Ver estado de los servicios
docker-compose ps

# Ver logs en tiempo real
docker-compose logs -f

# Eliminar todo (incluyendo vol√∫menes)
docker-compose down -v
```

### Interacci√≥n con HDFS

```powershell
# Conectarse al NameNode
docker exec -it hadoop_namenode bash

# Listar archivos en HDFS
hdfs dfs -ls /

# Ver contenido de un archivo
hdfs dfs -cat /input/human_answers.txt | head -10

# Verificar salud del cluster
hdfs dfsadmin -report

# Ver uso de espacio
hdfs dfs -du -h /
```

### Ejecutar An√°lisis Manualmente

Si necesitas re-ejecutar el an√°lisis:

```powershell
# Eliminar outputs anteriores
docker exec -it hadoop_namenode hdfs dfs -rm -r /output/*

# Ejecutar an√°lisis de nuevo
docker exec -it hadoop_namenode bash /scripts/run-analysis.sh
```

---

## üßπ Limpieza

Para limpiar completamente el entorno:

```powershell
# Detener y eliminar contenedores
docker-compose down

# Eliminar vol√∫menes (datos persistentes)
docker-compose down -v

# Eliminar im√°genes construidas
docker rmi $(docker images | grep 't3' | awk '{print $3}')

# Limpiar sistema Docker completo (opcional)
docker system prune -a
```

---

## Troubleshooting

### Problema: PostgreSQL no inicia

**Error**: `FATAL: data directory "/var/lib/postgresql/data" has wrong ownership`

**Soluci√≥n**:
```powershell
docker-compose down -v
docker-compose up -d postgres
```

### Problema: NameNode no formatea

**Error**: `NameNode is not formatted`

**Soluci√≥n**:
```powershell
docker exec -it hadoop_namenode hdfs namenode -format -force
docker-compose restart namenode
```

### Problema: DataNode no se conecta

**Error**: `DataNode: Incompatible clusterIDs`

**Soluci√≥n**:
```powershell
docker-compose down
docker volume rm t3_datanode_data t3_namenode_data
docker-compose up -d
```

### Problema: Pig no encuentra archivos

**Error**: `Input path does not exist`

**Soluci√≥n**:
```powershell
# Verificar que los archivos est√©n en HDFS
docker exec -it hadoop_namenode hdfs dfs -ls /input/

# Si no est√°n, copiarlos manualmente
docker exec -it hadoop_namenode bash
hdfs dfs -put /data/export/human_answers.txt /input/
hdfs dfs -put /data/export/llm_answers.txt /input/
hdfs dfs -put /data/stopwords.txt /input/
```

### Verificar salud del sistema

```powershell
# Ver estado de servicios
docker-compose ps

# Verificar logs de errores
docker-compose logs | grep -i error

# Verificar conectividad entre contenedores
docker exec -it hadoop_namenode ping datanode
```

---

## Tecnologias Utilizadas

- **PostgreSQL 15**: Base de datos relacional
- **Hadoop 3.3.6**: Framework de procesamiento distribuido
- **Apache Pig 0.17.0**: Lenguaje de alto nivel para an√°lisis de datos
- **Docker & Docker Compose**: Containerizaci√≥n y orquestaci√≥n
- **Python 3.9**: Scripts de carga y exportaci√≥n
- **Java 8**: Runtime para Hadoop y Pig

---

## Estructura de Datos

### Schema de PostgreSQL

```sql
CREATE TABLE responses (
    id SERIAL PRIMARY KEY,
    question_id VARCHAR(50) NOT NULL,
    question TEXT NOT NULL,
    human_answer TEXT,
    llm_answer TEXT,
    source VARCHAR(20),
    score FLOAT,
    timestamp BIGINT
);
```

### Datos de Entrada

- **Total respuestas**: 9,738
- **Respuestas √∫nicas de humanos**: ~9,738
- **Respuestas del LLM**: ~9,738
- **Fuente**: Yahoo! Answers dataset

---

## Caracteristicas Implementadas

### Requisitos Cumplidos

- [x] **Ingesta de Datos**: Extracci√≥n desde PostgreSQL
- [x] **Ecosistema Hadoop**: HDFS configurado y funcionando
- [x] **Apache Pig**: Scripts de an√°lisis implementados
- [x] **Tokenizaci√≥n**: Separaci√≥n en palabras individuales
- [x] **Limpieza**: Min√∫sculas, eliminaci√≥n de puntuaci√≥n
- [x] **Filtrado de Stopwords**: Lista espa√±ol/ingl√©s
- [x] **Conteo (WordCount)**: Frecuencia de palabras
- [x] **An√°lisis Comparativo**: Humanos vs LLM por separado
- [x] **Docker**: Completamente containerizado
- [x] **Docker Compose**: Orquestaci√≥n de servicios

### Caracteristicas Adicionales

- [x] Top 100 palabras m√°s frecuentes por cada conjunto
- [x] An√°lisis de diferencias entre conjuntos
- [x] Interfaces web para monitoreo (Hadoop UI, YARN)
- [x] Scripts de inicializaci√≥n autom√°tica
- [x] Healthchecks para servicios
- [x] Persistencia de datos con vol√∫menes Docker

---

## Autor

**Tarea 3 - Sistemas Distribuidos 2025-2**

---

## Licencia

Este proyecto es parte de una tarea acad√©mica para el curso de Sistemas Distribuidos.

---

## Agradecimientos

- Dataset basado en Yahoo! Answers
- Apache Hadoop y Apache Pig communities
- Docker community

---

## Soporte

Si encuentras problemas:

1. Revisa la secci√≥n de **Troubleshooting**
2. Verifica los logs: `docker-compose logs`
3. Aseg√∫rate de tener suficiente RAM (8GB+)
4. Verifica que los puertos 5432, 9000, 9870, 9864, 8088 est√©n libres

---

**Listo para ejecutar!**

```powershell
docker-compose up -d
docker-compose logs -f pig_analysis
```

Espera aproximadamente 5-10 minutos para que todo el proceso se complete.
